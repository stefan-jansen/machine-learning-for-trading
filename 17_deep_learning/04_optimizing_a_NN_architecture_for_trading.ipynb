{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Deep NN to predict Asset Price returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we need to explore variations of the design options outlined above because we can rarely be sure from the outset which network architecture best suits the data.\n",
    "\n",
    "In this section, we will explore various options to build a simple feedforward Neural Network to predict asset price returns for a one-day horizon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:38.291434Z",
     "start_time": "2021-02-23T05:45:38.289510Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.954191Z",
     "start_time": "2021-02-23T05:45:38.293938Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "from ast import literal_eval as make_tuple\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.958084Z",
     "start_time": "2021-02-23T05:45:39.955234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.968456Z",
     "start_time": "2021-02-23T05:45:39.959253Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:39.992331Z",
     "start_time": "2021-02-23T05:45:39.969458Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:40.004488Z",
     "start_time": "2021-02-23T05:45:39.993389Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_STORE = '../data/assets.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:40.012549Z",
     "start_time": "2021-02-23T05:45:40.006305Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir()\n",
    "    \n",
    "checkpoint_path = results_path / 'logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a stock return series to predict asset price moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop our trading strategy, we use the daily stock returns for some 995 US stocks for the eight year period from 2010 to 2017, and the features developed in Chapter 12 that include volatility and momentum factors as well as lagged returns with cross-sectional and sectoral rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:42.078013Z",
     "start_time": "2021-02-23T05:45:40.014012Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../12_gradient_boosting_machines/data.h5', 'model_data').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:42.090238Z",
     "start_time": "2021-02-23T05:45:42.079584Z"
    }
   },
   "outputs": [],
   "source": [
    "outcomes = data.filter(like='fwd').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:42.105424Z",
     "start_time": "2021-02-23T05:45:42.091504Z"
    }
   },
   "outputs": [],
   "source": [
    "lookahead = 1\n",
    "outcome= f'r{lookahead:02}_fwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.061968Z",
     "start_time": "2021-02-23T05:45:42.106337Z"
    }
   },
   "outputs": [],
   "source": [
    "X_cv = data.loc[idx[:, :'2017'], :].drop(outcomes, axis=1)\n",
    "y_cv = data.loc[idx[:, :'2017'], outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.160579Z",
     "start_time": "2021-02-23T05:45:43.063097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cv.index.get_level_values('symbol').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.269555Z",
     "start_time": "2021-02-23T05:45:43.161556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1911344 entries, ('A', Timestamp('2010-04-06 00:00:00')) to ('ZION', Timestamp('2017-11-29 00:00:00'))\n",
      "Data columns (total 30 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   dollar_vol_rank  1911344 non-null  float64\n",
      " 1   rsi              1911344 non-null  float64\n",
      " 2   bb_high          1911344 non-null  float64\n",
      " 3   bb_low           1911344 non-null  float64\n",
      " 4   NATR             1911344 non-null  float64\n",
      " 5   ATR              1911344 non-null  float64\n",
      " 6   PPO              1911344 non-null  float64\n",
      " 7   MACD             1911344 non-null  float64\n",
      " 8   sector           1911344 non-null  int64  \n",
      " 9   r01              1911344 non-null  float64\n",
      " 10  r05              1911344 non-null  float64\n",
      " 11  r10              1911344 non-null  float64\n",
      " 12  r21              1911344 non-null  float64\n",
      " 13  r42              1911344 non-null  float64\n",
      " 14  r63              1911344 non-null  float64\n",
      " 15  r01dec           1911344 non-null  float64\n",
      " 16  r05dec           1911344 non-null  float64\n",
      " 17  r10dec           1911344 non-null  float64\n",
      " 18  r21dec           1911344 non-null  float64\n",
      " 19  r42dec           1911344 non-null  float64\n",
      " 20  r63dec           1911344 non-null  float64\n",
      " 21  r01q_sector      1911344 non-null  float64\n",
      " 22  r05q_sector      1911344 non-null  float64\n",
      " 23  r10q_sector      1911344 non-null  float64\n",
      " 24  r21q_sector      1911344 non-null  float64\n",
      " 25  r42q_sector      1911344 non-null  float64\n",
      " 26  r63q_sector      1911344 non-null  float64\n",
      " 27  year             1911344 non-null  int64  \n",
      " 28  month            1911344 non-null  int64  \n",
      " 29  weekday          1911344 non-null  int64  \n",
      "dtypes: float64(26), int64(4)\n",
      "memory usage: 445.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_cv.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate model generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `make_model` function illustrates how to flexibly define various architectural elements for the search process. The dense_layers argument defines both the depth and width of the network as a list of integers. We also use dropout for regularization, expressed as a float in the range [0, 1] to define the probability that a given unit will be excluded from a training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.275796Z",
     "start_time": "2021-02-23T05:45:43.271059Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(dense_layers, activation, dropout):\n",
    "    '''Creates a multi-layer perceptron model\n",
    "    \n",
    "    dense_layers: List of layer sizes; one number per layer\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "    for i, layer_size in enumerate(dense_layers, 1):\n",
    "        if i == 1:\n",
    "            model.add(Dense(layer_size, input_dim=X_cv.shape[1]))\n",
    "            model.add(Activation(activation))\n",
    "        else:\n",
    "            model.add(Dense(layer_size))\n",
    "            model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='Adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate multiple configurations with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a training set for cross-validation, and keep the last 12 months with data as holdout test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.289179Z",
     "start_time": "2021-02-23T05:45:43.277271Z"
    }
   },
   "outputs": [],
   "source": [
    "n_splits = 12\n",
    "train_period_length=21 * 12 * 4\n",
    "test_period_length=21 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.297459Z",
     "start_time": "2021-02-23T05:45:43.290410Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                          train_period_length=train_period_length,\n",
    "                          test_period_length=test_period_length,\n",
    "                          lookahead=lookahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CV Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to define our Keras classifier using the make_model function, set cross-validation (see chapter 6 on The Machine Learning Process and following for the OneStepTimeSeriesSplit), and the parameters that we would like to explore. \n",
    "\n",
    "We pick several one- and two-layer configurations, relu and tanh activation functions, and different dropout rates. We could also try out different optimizers (but did not run this experiment to limit what is already a computationally intensive effort):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.305908Z",
     "start_time": "2021-02-23T05:45:43.298464Z"
    }
   },
   "outputs": [],
   "source": [
    "dense_layer_opts = [(16, 8), (32, 16), (32, 32), (64, 32)]\n",
    "activation_opts = ['tanh']\n",
    "dropout_opts = [0, .1, .2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.314388Z",
     "start_time": "2021-02-23T05:45:43.307047Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = list(product(dense_layer_opts, activation_opts, dropout_opts))\n",
    "np.random.shuffle(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.324946Z",
     "start_time": "2021-02-23T05:45:43.315355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trigger the parameter search, we instantiate a GridSearchCV object, define the fit_params that will be passed to the Keras modelâ€™s fit method, and provide the training data to the GridSearchCV fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:45:43.332302Z",
     "start_time": "2021-02-23T05:45:43.326769Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_valid_data(X, y, train_idx, test_idx):\n",
    "    x_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]\n",
    "    x_val, y_val = X.iloc[test_idx, :], y.iloc[test_idx]\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.397856Z",
     "start_time": "2021-02-23T05:45:43.333668Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32) tanh 0.1 64\n",
      "00:00:07 01 | 01 |  0.0013 |  0.0114\n",
      "00:00:14 01 | 02 |  0.0139 |  0.0063\n",
      "00:00:20 01 | 03 |  0.0078 |  0.0042\n",
      "00:00:26 01 | 04 |  0.0208 |  0.0130\n",
      "00:00:32 01 | 05 |  0.0035 |  0.0060\n",
      "00:00:38 01 | 06 |  0.0110 |  0.0064\n",
      "00:00:43 01 | 07 |  0.0233 |  0.0314\n",
      "00:00:49 01 | 08 |  0.0202 |  0.0213\n",
      "00:00:55 01 | 09 |  0.0170 |  0.0099\n",
      "00:01:02 01 | 10 | -0.0005 | -0.0036\n",
      "00:01:08 01 | 11 |  0.0257 |  0.0272\n",
      "00:01:14 01 | 12 |  0.0062 | -0.0091\n",
      "00:01:20 01 | 13 |  0.0011 |  0.0107\n",
      "00:01:26 01 | 14 |  0.0120 |  0.0092\n",
      "00:01:32 01 | 15 |  0.0058 |  0.0056\n",
      "00:01:38 01 | 16 |  0.0205 |  0.0250\n",
      "00:01:44 01 | 17 |  0.0139 |  0.0220\n",
      "00:01:49 01 | 18 |  0.0084 |  0.0035\n",
      "00:01:55 01 | 19 | -0.0113 | -0.0041\n",
      "00:02:01 01 | 20 | -0.0005 | -0.0189\n",
      "00:02:09 02 | 01 |  0.0024 | -0.0167\n",
      "00:02:15 02 | 02 |  0.0037 | -0.0021\n",
      "00:02:21 02 | 03 |  0.0115 |  0.0101\n",
      "00:02:27 02 | 04 |  0.0087 |  0.0125\n",
      "00:02:33 02 | 05 | -0.0025 | -0.0092\n",
      "00:02:39 02 | 06 |  0.0112 |  0.0215\n",
      "00:02:45 02 | 07 |  0.0185 |  0.0410\n",
      "00:02:52 02 | 08 | -0.0045 | -0.0036\n",
      "00:02:58 02 | 09 |  0.0135 |  0.0264\n",
      "00:03:04 02 | 10 |  0.0028 |  0.0021\n",
      "00:03:10 02 | 11 |  0.0189 |  0.0252\n",
      "00:03:16 02 | 12 |  0.0258 |  0.0365\n",
      "00:03:22 02 | 13 |  0.0110 |  0.0083\n",
      "00:03:28 02 | 14 |  0.0108 |  0.0152\n",
      "00:03:35 02 | 15 |  0.0151 |  0.0229\n",
      "00:03:40 02 | 16 |  0.0178 |  0.0349\n",
      "00:03:46 02 | 17 |  0.0103 |  0.0205\n",
      "00:03:52 02 | 18 |  0.0048 |  0.0378\n",
      "00:03:58 02 | 19 |  0.0081 |  0.0085\n",
      "00:04:03 02 | 20 | -0.0130 | -0.0007\n",
      "00:04:10 03 | 01 | -0.0133 | -0.0115\n",
      "00:04:15 03 | 02 |  0.0086 |  0.0164\n",
      "00:04:21 03 | 03 |  0.0032 | -0.0030\n",
      "00:04:26 03 | 04 | -0.0186 | -0.0537\n",
      "00:04:32 03 | 05 |  0.0038 |  0.0205\n",
      "00:04:38 03 | 06 |  0.0046 | -0.0029\n",
      "00:04:43 03 | 07 |  0.0214 |  0.0373\n",
      "00:04:49 03 | 08 | -0.0104 | -0.0124\n",
      "00:04:54 03 | 09 |  0.0193 |  0.0246\n",
      "00:05:00 03 | 10 |  0.0260 |  0.0292\n",
      "00:05:06 03 | 11 |  0.0044 | -0.0002\n",
      "00:05:11 03 | 12 | -0.0012 | -0.0114\n",
      "00:05:17 03 | 13 | -0.0151 | -0.0542\n",
      "00:05:23 03 | 14 | -0.0212 | -0.0157\n",
      "00:05:28 03 | 15 | -0.0006 | -0.0045\n",
      "00:05:34 03 | 16 | -0.0092 | -0.0068\n",
      "00:05:40 03 | 17 |  0.0042 |  0.0002\n",
      "00:05:47 03 | 18 | -0.0306 | -0.0400\n",
      "00:05:53 03 | 19 | -0.0078 | -0.0062\n",
      "00:05:60 03 | 20 |  0.0175 |  0.0256\n",
      "00:06:06 04 | 01 | -0.0417 | -0.0668\n",
      "00:06:13 04 | 02 |  0.0161 |  0.0251\n",
      "00:06:19 04 | 03 |  0.0237 |  0.0014\n",
      "00:06:25 04 | 04 | -0.0485 | -0.0664\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a04299cd19cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 model.fit(x_train,\n\u001b[0m\u001b[1;32m     20\u001b[0m                           \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ml4t-dl/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ic = []\n",
    "scaler = StandardScaler()\n",
    "for params in param_grid:\n",
    "    dense_layers, activation, dropout = params\n",
    "    for batch_size in [64, 256]:\n",
    "        print(dense_layers, activation, dropout, batch_size)\n",
    "        checkpoint_dir = checkpoint_path / str(dense_layers) / activation / str(dropout) / str(batch_size)\n",
    "        if not checkpoint_dir.exists():\n",
    "            checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        start = time()\n",
    "        for fold, (train_idx, test_idx) in enumerate(cv.split(X_cv)):\n",
    "            x_train, y_train, x_val, y_val = get_train_valid_data(X_cv, y_cv, train_idx, test_idx)\n",
    "            x_train = scaler.fit_transform(x_train)\n",
    "            x_val = scaler.transform(x_val)\n",
    "            preds = y_val.to_frame('actual')\n",
    "            r = pd.DataFrame(index=y_val.groupby(level='date').size().index)\n",
    "            model = make_model(dense_layers, activation, dropout)\n",
    "            for epoch in range(20):            \n",
    "                model.fit(x_train,\n",
    "                          y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=1,\n",
    "                          verbose=0,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(x_val, y_val))\n",
    "                model.save_weights((checkpoint_path / f'ckpt_{fold}_{epoch}').as_posix())\n",
    "                preds[epoch] = model.predict(x_val).squeeze()\n",
    "                r[epoch] = preds.groupby(level='date').apply(lambda x: spearmanr(x.actual, x[epoch])[0]).to_frame(epoch)\n",
    "                print(format_time(time()-start), f'{fold + 1:02d} | {epoch + 1:02d} | {r[epoch].mean():7.4f} | {r[epoch].median():7.4f}')\n",
    "            ic.append(r.assign(dense_layers=str(dense_layers), \n",
    "                               activation=activation, \n",
    "                               dropout=dropout,\n",
    "                               batch_size=batch_size,\n",
    "                               fold=fold))       \n",
    "\n",
    "        t = time()-start\n",
    "        pd.concat(ic).to_hdf(results_path / 'scores.h5', 'ic_by_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictive performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.399489Z",
     "start_time": "2021-02-23T05:45:38.349Z"
    }
   },
   "outputs": [],
   "source": [
    "params = ['dense_layers', 'dropout', 'batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.400398Z",
     "start_time": "2021-02-23T05:45:38.351Z"
    }
   },
   "outputs": [],
   "source": [
    "ic = pd.read_hdf(results_path / 'scores.h5', 'ic_by_day').drop('activation', axis=1)\n",
    "ic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.401296Z",
     "start_time": "2021-02-23T05:45:38.353Z"
    }
   },
   "outputs": [],
   "source": [
    "ic.groupby(params).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.402062Z",
     "start_time": "2021-02-23T05:45:38.355Z"
    }
   },
   "outputs": [],
   "source": [
    "ic_long = pd.melt(ic, id_vars=params + ['fold'], var_name='epoch', value_name='ic')\n",
    "ic_long.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.402928Z",
     "start_time": "2021-02-23T05:45:38.357Z"
    }
   },
   "outputs": [],
   "source": [
    "ic_long = ic_long.groupby(params+ ['epoch', 'fold']).ic.mean().to_frame('ic').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.403975Z",
     "start_time": "2021-02-23T05:45:38.360Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(x='epoch', y='ic', col='dense_layers', row='dropout', \n",
    "                data=ic_long[ic_long.dropout>0], kind='line')\n",
    "g.map(plt.axhline, y=0, ls='--', c='k', lw=1)\n",
    "g.savefig(results_path / 'ic_lineplot', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.404731Z",
     "start_time": "2021-02-23T05:45:38.362Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_ols(ic):\n",
    "    ic.dense_layers = ic.dense_layers.str.replace(', ', '-').str.replace('(', '').str.replace(')', '')\n",
    "    data = pd.melt(ic, id_vars=params, var_name='epoch', value_name='ic')\n",
    "    data.epoch = data.epoch.astype(int).astype(str).apply(lambda x: f'{int(x):02.0f}')\n",
    "    model_data = pd.get_dummies(data.sort_values(params + ['epoch']), columns=['epoch'] + params, drop_first=True).sort_index(1)\n",
    "    model_data.columns = [s.split('_')[-1] for s in model_data.columns]\n",
    "    model = sm.OLS(endog=model_data.ic, exog=sm.add_constant(model_data.drop('ic', axis=1)))\n",
    "    return model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.405558Z",
     "start_time": "2021-02-23T05:45:38.364Z"
    }
   },
   "outputs": [],
   "source": [
    "model = run_ols(ic.drop('fold', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.406263Z",
     "start_time": "2021-02-23T05:45:38.366Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.407080Z",
     "start_time": "2021-02-23T05:45:38.367Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "ci = model.conf_int()\n",
    "errors = ci[1].sub(ci[0]).div(2)\n",
    "\n",
    "coefs = (model.params.to_frame('coef').assign(error=errors)\n",
    "         .reset_index().rename(columns={'index': 'variable'}))\n",
    "coefs = coefs[~coefs['variable'].str.startswith('date') & (coefs.variable != 'const')]\n",
    "\n",
    "coefs.plot(x='variable', y='coef', kind='bar',\n",
    "           ax=ax, color='none', capsize=3,\n",
    "           yerr='error', legend=False, rot=0, title='Impact of Architecture and Training Parameters on Out-of-Sample Performance')\n",
    "ax.set_ylabel('IC')\n",
    "ax.set_xlabel('')\n",
    "ax.scatter(x=pd.np.arange(len(coefs)), marker='_', s=120, y=coefs['coef'], color='black')\n",
    "ax.axhline(y=0, linestyle='--', color='black', linewidth=1)\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "\n",
    "ax.annotate('Batch Size', xy=(.02, -0.1), xytext=(.02, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=1.3, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "ax.annotate('Layers', xy=(.1, -0.1), xytext=(.1, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=4.8, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "ax.annotate('Dropout', xy=(.2, -0.1), xytext=(.2, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=2.8, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "ax.annotate('Epochs', xy=(.62, -0.1), xytext=(.62, -0.2),\n",
    "            xycoords='axes fraction',\n",
    "            textcoords='axes fraction',\n",
    "            fontsize=11, ha='center', va='bottom',\n",
    "            bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=30.5, lengthB=1.0', lw=1.0, color='black'))\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path / 'ols_coef', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.407955Z",
     "start_time": "2021-02-23T05:45:38.370Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_params(n=5):\n",
    "    \"\"\"Get the best parameters across all folds by daily median IC\"\"\"\n",
    "    params = ['dense_layers', 'activation', 'dropout', 'batch_size']\n",
    "    ic = pd.read_hdf(results_path / 'scores.h5', 'ic_by_day').drop('fold', axis=1)\n",
    "    dates = sorted(ic.index.unique())\n",
    "    train_period = 24 * 21\n",
    "    train_dates = dates[:train_period]\n",
    "    ic = ic.loc[train_dates]\n",
    "    return (ic.groupby(params)\n",
    "            .median()\n",
    "            .stack()\n",
    "            .to_frame('ic')\n",
    "            .reset_index()\n",
    "            .rename(columns={'level_4': 'epoch'})\n",
    "            .nlargest(n=n, columns='ic')\n",
    "            .drop('ic', axis=1)\n",
    "            .to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.408720Z",
     "start_time": "2021-02-23T05:45:38.373Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_predictions(dense_layers, activation, dropout, batch_size, epoch):\n",
    "    data = pd.read_hdf('../12_gradient_boosting_machines/data.h5', 'model_data').dropna()\n",
    "    outcomes = data.filter(like='fwd').columns.tolist()\n",
    "    X_cv = data.loc[idx[:, :'2017'], :].drop(outcomes, axis=1)\n",
    "    input_dim = X_cv.shape[1]\n",
    "    y_cv = data.loc[idx[:, :'2017'], 'r01_fwd']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    predictions = []\n",
    "    \n",
    "    do = '0' if str(dropout) == '0.0' else str(dropout)\n",
    "    checkpoint_dir = checkpoint_path / dense_layers / activation / do / str(batch_size)\n",
    "        \n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X_cv)):\n",
    "        x_train, y_train, x_val, y_val = get_train_valid_data(X_cv, y_cv, train_idx, test_idx)\n",
    "        x_val = scaler.fit(x_train).transform(x_val)\n",
    "        model = make_model(make_tuple(dense_layers), activation, dropout)\n",
    "        status = model.load_weights((checkpoint_dir / f'ckpt_{fold}_{epoch}').as_posix())\n",
    "        status.expect_partial()\n",
    "        predictions.append(pd.Series(model.predict(x_val).squeeze(), index=y_val.index))\n",
    "    return pd.concat(predictions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T05:52:12.409529Z",
     "start_time": "2021-02-23T05:45:38.375Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = get_best_params()\n",
    "predictions = []\n",
    "for i, params in enumerate(best_params):\n",
    "    predictions.append(generate_predictions(**params).to_frame(i))\n",
    "\n",
    "predictions = pd.concat(predictions, axis=1)\n",
    "print(predictions.info())\n",
    "predictions.to_hdf(results_path / 'test_preds.h5', 'predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to further improve the results\n",
    "\n",
    "The relatively simple architecture yields some promising results. To further improve performance, you can\n",
    "- First and foremost, add new features and more data to the model\n",
    "- Expand the set of architectures to explore, including more or wider layers\n",
    "- Inspect the training progress and train for more epochs if the validation error continued to improve at 50 epochs\n",
    "\n",
    "Finally, you can use more sophisticated architectures, including Recurrent Neural Networks (RNN) and Convolutional Neural Networks that are well suited to sequential data, whereas vanilla feedforward NNs are not designed to capture the ordered nature of the features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
